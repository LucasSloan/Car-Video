6 layer transformer, batch size 20, SGD learning rate 5.0
epoch 1 loss: 3.03
epoch 2 loss: 3.02
epoch 3 loss: 2.96